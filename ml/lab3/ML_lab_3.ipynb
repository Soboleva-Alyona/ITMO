{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qSFPOWRc4oUg"
   },
   "source": [
    "## Подготовка данных\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ouu7OCwY8jZx"
   },
   "source": [
    "Выбранный текст - Человек, который принял жену за шляпу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3wIk-ZuVB8wb"
   },
   "outputs": [],
   "source": [
    "#constants \n",
    "file_name = 'Человек,который_принял_жену_за_шляпу.pdf' # реальный текст романа с 14 по 112 страницы \n",
    "sentence_len = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CvhBHbdn4gQU",
    "outputId": "928edf99-81fa-451c-e5ec-2aa9fe9dbf2f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pdfquery in /Users/esoboleva/Library/Python/3.8/lib/python/site-packages (0.4.3)\n",
      "Requirement already satisfied: pyquery>=1.2.2 in /Users/esoboleva/Library/Python/3.8/lib/python/site-packages (from pdfquery) (2.0.0)\n",
      "Requirement already satisfied: chardet in /Users/esoboleva/Library/Python/3.8/lib/python/site-packages (from pdfquery) (5.1.0)\n",
      "Requirement already satisfied: cssselect>=0.7.1 in /Users/esoboleva/Library/Python/3.8/lib/python/site-packages (from pdfquery) (1.2.0)\n",
      "Requirement already satisfied: pdfminer.six in /Users/esoboleva/Library/Python/3.8/lib/python/site-packages (from pdfquery) (20221105)\n",
      "Requirement already satisfied: lxml>=3.0 in /Users/esoboleva/Library/Python/3.8/lib/python/site-packages (from pdfquery) (4.9.2)\n",
      "Requirement already satisfied: roman>=1.4.0 in /Users/esoboleva/Library/Python/3.8/lib/python/site-packages (from pdfquery) (4.0)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /Users/esoboleva/Library/Python/3.8/lib/python/site-packages (from pdfminer.six->pdfquery) (40.0.2)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /Users/esoboleva/Library/Python/3.8/lib/python/site-packages (from pdfminer.six->pdfquery) (3.1.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/esoboleva/Library/Python/3.8/lib/python/site-packages (from cryptography>=36.0.0->pdfminer.six->pdfquery) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /Users/esoboleva/Library/Python/3.8/lib/python/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->pdfquery) (2.21)\n",
      "\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.0.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.1.1\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001B[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /Library/Python/3.8/site-packages (1.5.3)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /Users/esoboleva/Library/Python/3.8/lib/python/site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Python/3.8/site-packages (from pandas) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Library/Python/3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas) (1.15.0)\n",
      "\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.0.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.1.1\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001B[0m\n",
      "Requirement already satisfied: nltk in /Users/esoboleva/Library/Python/3.8/lib/python/site-packages (3.8.1)\n",
      "Requirement already satisfied: tqdm in /Users/esoboleva/Library/Python/3.8/lib/python/site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/esoboleva/Library/Python/3.8/lib/python/site-packages (from nltk) (2023.3.23)\n",
      "Requirement already satisfied: click in /Users/esoboleva/Library/Python/3.8/lib/python/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in /Library/Python/3.8/site-packages (from nltk) (1.2.0)\n",
      "\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.0.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.1.1\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001B[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /Users/esoboleva/Library/Python/3.8/lib/python/site-packages (1.24.3)\n",
      "\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.0.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.1.1\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001B[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /Users/esoboleva/Library/Python/3.8/lib/python/site-packages (2.0.0)\n",
      "Requirement already satisfied: filelock in /Users/esoboleva/Library/Python/3.8/lib/python/site-packages (from torch) (3.12.0)\n",
      "Requirement already satisfied: sympy in /Users/esoboleva/Library/Python/3.8/lib/python/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/esoboleva/Library/Python/3.8/lib/python/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/esoboleva/Library/Python/3.8/lib/python/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: typing-extensions in /Users/esoboleva/Library/Python/3.8/lib/python/site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/esoboleva/Library/Python/3.8/lib/python/site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/esoboleva/Library/Python/3.8/lib/python/site-packages (from sympy->torch) (1.3.0)\n",
      "\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.0.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.1.1\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install pdfquery\n",
    "! pip install pandas\n",
    "! pip install --user -U nltk\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install numpy\n",
    "\n",
    "! pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "from pdfquery import PDFQuery\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import nltk\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import re\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "1eSu568VFLYF"
   },
   "outputs": [],
   "source": [
    "pdf = PDFQuery(file_name)\n",
    "pdf.load(*range(13, 30)) #TODO(\"увеличить?\")\n",
    "\n",
    "text_elements = pdf.pq('LTTextLineHorizontal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yVs0MDc9XEkM",
    "outputId": "c4b588ed-d3e9-46e2-9b79-8ef464d608d0"
   },
   "outputs": [],
   "source": [
    "text = \"\".join([t.text for t in text_elements]).replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ZsWeHIQ-W_P",
    "outputId": "e75e5e92-6996-4e96-b384-f2c04d718fb0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/esoboleva/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "RxCpOdODax5n"
   },
   "outputs": [],
   "source": [
    "def tokenize_ru(file_text):\n",
    "    # firstly let's apply nltk tokenization\n",
    "    tokens = word_tokenize(file_text)\n",
    "\n",
    "    # let's delete punctuation symbols\n",
    "    tokens = [i for i in tokens if (i not in string.punctuation)]\n",
    "\n",
    "    # deleting other symbols\n",
    "    punct = ['—', ',', '.', '...']\n",
    "    tokens = [i for i in tokens if (i not in punct)]\n",
    "\n",
    "    # cleaning words\n",
    "    tokens = [re.sub(\"[a-z]\",\"\", re.sub(\"[0-9]\",\"\",\n",
    "              i.replace(\"«\", \"\")\n",
    "              .replace(\"»\", \"\")\n",
    "              .replace(\".\", \"\")\n",
    "              .replace(\"-\", \"\")\n",
    "              .replace('—', \"\")\n",
    "              .replace(',', \"\")\n",
    "              .replace('`', \"\")\n",
    "                                        \n",
    "              .lower()))\n",
    "              for i in tokens]\n",
    "    \n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "kHN6VvpEax5o"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sent_tokenize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m sentences \u001B[38;5;241m=\u001B[39m [tokenize_ru(sent) \u001B[38;5;28;01mfor\u001B[39;00m sent \u001B[38;5;129;01min\u001B[39;00m \u001B[43msent_tokenize\u001B[49m(text)]\n",
      "\u001B[0;31mNameError\u001B[0m: name 'sent_tokenize' is not defined"
     ]
    }
   ],
   "source": [
    "sentences = [tokenize_ru(sent) for sent in sent_tokenize(text, 'russian')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oah7wL8max5q",
    "outputId": "d5082a45-23a4-44d2-f987-4c801654b81f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', 'а', 'б', 'в', 'г', 'д', 'е', 'ж', 'з', 'и', 'й', 'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф', 'х', 'ц', 'ч', 'ш', 'щ', 'ъ', 'ы', 'ь', 'э', 'ю', 'я']\n"
     ]
    }
   ],
   "source": [
    "alphabet = {'\\n'}\n",
    "\n",
    "loaded_text_path = 'text.txt'\n",
    "text_file = open(loaded_text_path, \"w\")\n",
    "\n",
    "for s in sentences:\n",
    "    joined_s = \" \".join(s)\n",
    "    if len(joined_s) > sentence_len:\n",
    "        text_file.write(joined_s)\n",
    "        text_file.write('\\n')\n",
    "        # getting alphabet\n",
    "        for c in joined_s:\n",
    "            alphabet.add(c)\n",
    "text_file.close()\n",
    "alphabet = sorted(alphabet)\n",
    "print(alphabet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wWxqCwovax5r"
   },
   "source": [
    "остались только кириллица и пробел - ура\n",
    "\n",
    "сделаем one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "zBzT41Mjax5r"
   },
   "outputs": [],
   "source": [
    "text = open(\"text.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "qIk9X-wNax5s"
   },
   "outputs": [],
   "source": [
    "char_to_int = dict((c, i) for i, c in enumerate(alphabet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I_dJVdyHax5s",
    "outputId": "19ffba96-7786-421d-8d26-05cf79b86369"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  71224\n",
      "Total Vocab:  34\n"
     ]
    }
   ],
   "source": [
    "n_chars = len(text)\n",
    "n_vocab = len(alphabet)\n",
    "print(\"Total Characters: \", n_chars)\n",
    "print(\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9aKmqq-Wax5s",
    "outputId": "aaab0bf6-3a8e-4e9d-d4c5-41c78394a27c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  71124\n"
     ]
    }
   ],
   "source": [
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "\tseq_in = text[i:i + seq_length]\n",
    "\tseq_out = text[i + seq_length]\n",
    "\tdataX.append([char_to_int[char] for char in seq_in])\n",
    "\tdataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "FnZiWiyqax5t"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([71124, 100, 1]) torch.Size([71124])\n"
     ]
    }
   ],
   "source": [
    "# reshape X to be [samples, time steps, features] \n",
    "X = torch.tensor(dataX, dtype=torch.float32).reshape(n_patterns, seq_length, 1)\n",
    "X = X / float(n_vocab)\n",
    "y = torch.tensor(dataY)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oAGY8ezK4sCU"
   },
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "4RvEwPWZax5u"
   },
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=1, hidden_size=256, num_layers=1, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.linear = nn.Linear(256, n_vocab)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        # take only the last output\n",
    "        x = x[:, -1, :]\n",
    "        # produce output\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Cross-entropy: 13.0505\n",
      "Epoch 1: Cross-entropy: 12.8368\n",
      "Epoch 2: Cross-entropy: 12.7028\n",
      "Epoch 3: Cross-entropy: 12.5713\n",
      "Epoch 4: Cross-entropy: 12.4261\n",
      "Epoch 5: Cross-entropy: 12.2570\n",
      "Epoch 6: Cross-entropy: 12.0824\n",
      "Epoch 7: Cross-entropy: 11.8200\n",
      "Epoch 8: Cross-entropy: 11.6235\n",
      "Epoch 9: Cross-entropy: 11.3298\n",
      "Epoch 10: Cross-entropy: 11.0551\n",
      "Epoch 11: Cross-entropy: 10.8084\n",
      "Epoch 12: Cross-entropy: 10.5372\n",
      "Epoch 13: Cross-entropy: 10.2898\n",
      "Epoch 14: Cross-entropy: 10.0433\n",
      "Epoch 15: Cross-entropy: 9.7807\n",
      "Epoch 16: Cross-entropy: 9.5923\n",
      "Epoch 17: Cross-entropy: 9.3388\n",
      "Epoch 18: Cross-entropy: 9.0090\n",
      "Epoch 19: Cross-entropy: 8.8162\n",
      "Epoch 20: Cross-entropy: 8.5884\n",
      "Epoch 21: Cross-entropy: 8.3983\n",
      "Epoch 22: Cross-entropy: 8.2170\n",
      "Epoch 23: Cross-entropy: 8.0129\n",
      "Epoch 24: Cross-entropy: 7.7941\n",
      "Epoch 25: Cross-entropy: 7.5952\n",
      "Epoch 26: Cross-entropy: 7.4704\n",
      "Epoch 27: Cross-entropy: 7.4840\n",
      "Epoch 28: Cross-entropy: 7.1478\n",
      "Epoch 29: Cross-entropy: 7.0355\n",
      "900.5380249023438\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 30\n",
    "batch_size = 128\n",
    "model = RNNModel()\n",
    " \n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loader = DataLoader(TensorDataset(X, y), shuffle=True, batch_size=batch_size)\n",
    "\n",
    "best_model = None\n",
    "best_loss = np.inf\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in loader:\n",
    "        y_pred = model(X_batch)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in loader:\n",
    "            y_pred = model(X_batch)\n",
    "            loss += loss_fn(y_pred, y_batch)\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            best_model = model.state_dict()\n",
    "        print(\"Epoch %d: Cross-entropy: %.4f\" % (epoch, loss / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save([best_model, char_to_int], \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('text.txt', 'r')\n",
    "lines = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_len = 15\n",
    "sentence = np.random.randint(len(lines))\n",
    "prompt = lines[sentence][0:prompt_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real sentence:\n",
      " я попросил профессора вообразить что он подходит к одной из наших площадей с севера\n",
      "\n",
      "Prompt: \"я попросил проф\"\n",
      "я попросил профессора п ракиесил м порертотетюни кан п м с но с н мрриц полазало т мого соеа не полушариим с лимо раз иетоос короя и стоанн поомес ле оонаже о болаз веестиве но все еа ррланаз те оо р селеном  пз зоие о брлр исийиоу ттади н сооеитине нореро порано пе днзе поерат челныеооие м п помогний и оенафоним моииа в оорееений ни пасвкини и коинил бно зап что ое тан втль и кр поимени о ракоти сторенно ие пиисториео иаиас помо посгреа отириятс  с пам стляко поиибног  оне оизедвлия иоторию болезни оакять аес\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "pattern = [char_to_int[c] for c in prompt]\n",
    "\n",
    "int_to_char = dict((i, c) for c, i in char_to_int.items())\n",
    "\n",
    "model.eval()\n",
    "print(\"Real sentence:\\n\", lines[sentence])\n",
    "print('Prompt: \"%s\"' % prompt)\n",
    "print(prompt, end=\"\")\n",
    "with torch.no_grad():\n",
    "    for i in range(500):\n",
    "        # format input array of int into PyTorch tensor\n",
    "        x = np.reshape(pattern, (1, len(pattern), 1)) / float(n_vocab)\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "        # generate logits as output from the model\n",
    "        prediction = model(x)\n",
    "        # convert logits into one character\n",
    "        index = int(prediction.argmax())\n",
    "        result = int_to_char[index]\n",
    "        print(result, end=\"\")\n",
    "        # append the new character into the prompt for the next iteration\n",
    "        pattern.append(index)\n",
    "        pattern = pattern[1:]\n",
    "print()\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pgm1vifB4vnp"
   },
   "source": [
    "## Марковская цепь\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "WcGpS4nL46-W"
   },
   "outputs": [],
   "source": [
    "n_chars_to_consider = 6\n",
    "transitions = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-KYqL3Sjax5v"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transitions count:  30779\n"
     ]
    }
   ],
   "source": [
    "for s in lines:\n",
    "    prev = None\n",
    "    i = 0\n",
    "    while i < len(s):\n",
    "        if prev == None:\n",
    "            prev = s[:n_chars_to_consider]\n",
    "            i += n_chars_to_consider\n",
    "            continue\n",
    "        new_state = prev[1:] + s[i]\n",
    "        key = prev + '->' + new_state\n",
    "        if not (key in transitions):\n",
    "            transitions[key] = 1\n",
    "        else:\n",
    "            transitions[key] += 1\n",
    "        prev = new_state\n",
    "        i+=1\n",
    "\n",
    "# нормируем\n",
    "summ = 0\n",
    "for t in transitions.values():\n",
    "    summ += t\n",
    "\n",
    "transitions = {k: v / summ for k, v in transitions.items()}\n",
    "print(\"Transitions count: \", len(transitions.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m prompt_len \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m11\u001B[39m \u001B[38;5;66;03m# > n_chars_to_consider\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m sentence \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mrandint(\u001B[38;5;28mlen\u001B[39m(lines))\n\u001B[1;32m      4\u001B[0m prompt \u001B[38;5;241m=\u001B[39m lines[sentence][\u001B[38;5;241m0\u001B[39m:prompt_len]\n",
      "\u001B[0;31mNameError\u001B[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "prompt_len = 11 # > n_chars_to_consider\n",
    "\n",
    "sentence = np.random.randint(len(lines))\n",
    "prompt = lines[sentence][0:prompt_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real sentence:\n",
      " он должен был мысленно пересечь ее и рассказать мне мимо каких зданий проходит\n",
      "\n",
      "Prompt: \"он должен б\"\n",
      "он должен бы\n",
      "он должен был\n",
      "он должен был \n",
      "он должен был м\n",
      "он должен был мы\n",
      "он должен был мыс\n",
      "он должен был мысл\n",
      "он должен был мысле\n",
      "он должен был мыслен\n",
      "он должен был мысленн\n",
      "он должен был мысленно\n",
      "он должен был мысленно \n",
      "он должен был мысленно п\n",
      "он должен был мысленно пе\n",
      "он должен был мысленно пер\n",
      "он должен был мысленно пере\n",
      "он должен был мысленно перес\n",
      "он должен был мысленно пересе\n",
      "он должен был мысленно пересеч\n",
      "он должен был мысленно пересечь\n",
      "он должен был мысленно пересечь \n",
      "он должен был мысленно пересечь е\n",
      "он должен был мысленно пересечь ее\n",
      "он должен был мысленно пересечь ее \n",
      "он должен был мысленно пересечь ее и\n",
      "он должен был мысленно пересечь ее и \n",
      "он должен был мысленно пересечь ее и р\n",
      "он должен был мысленно пересечь ее и ра\n",
      "он должен был мысленно пересечь ее и рас\n",
      "он должен был мысленно пересечь ее и расс\n",
      "он должен был мысленно пересечь ее и расск\n",
      "он должен был мысленно пересечь ее и расска\n",
      "он должен был мысленно пересечь ее и рассказ\n",
      "он должен был мысленно пересечь ее и рассказа\n",
      "он должен был мысленно пересечь ее и рассказан\n",
      "он должен был мысленно пересечь ее и рассказанн\n",
      "он должен был мысленно пересечь ее и рассказанны\n",
      "он должен был мысленно пересечь ее и рассказанных\n",
      "он должен был мысленно пересечь ее и рассказанных \n",
      "он должен был мысленно пересечь ее и рассказанных н\n",
      "он должен был мысленно пересечь ее и рассказанных ни\n",
      "он должен был мысленно пересечь ее и рассказанных ниж\n",
      "он должен был мысленно пересечь ее и рассказанных ниже\n",
      "он должен был мысленно пересечь ее и рассказанных ниже \n",
      "он должен был мысленно пересечь ее и рассказанных ниже с\n",
      "он должен был мысленно пересечь ее и рассказанных ниже ст\n",
      "он должен был мысленно пересечь ее и рассказанных ниже стр\n",
      "он должен был мысленно пересечь ее и рассказанных ниже стра\n",
      "он должен был мысленно пересечь ее и рассказанных ниже стран\n",
      "он должен был мысленно пересечь ее и рассказанных ниже странн\n",
      "он должен был мысленно пересечь ее и рассказанных ниже странны\n",
      "он должен был мысленно пересечь ее и рассказанных ниже странных\n",
      "он должен был мысленно пересечь ее и рассказанных ниже странных \n",
      "он должен был мысленно пересечь ее и рассказанных ниже странных и\n",
      "он должен был мысленно пересечь ее и рассказанных ниже странных ис\n",
      "он должен был мысленно пересечь ее и рассказанных ниже странных ист\n",
      "он должен был мысленно пересечь ее и рассказанных ниже странных исто\n",
      "он должен был мысленно пересечь ее и рассказанных ниже странных истор\n",
      "он должен был мысленно пересечь ее и рассказанных ниже странных истори\n",
      "он должен был мысленно пересечь ее и рассказанных ниже странных история\n",
      "он должен был мысленно пересечь ее и рассказанных ниже странных историях\n",
      "он должен был мысленно пересечь ее и рассказанных ниже странных историях \n",
      "он должен был мысленно пересечь ее и рассказанных ниже странных историях п\n",
      "он должен был мысленно пересечь ее и рассказанных ниже странных историях по\n",
      "он должен был мысленно пересечь ее и рассказанных ниже странных историях пос\n",
      "он должен был мысленно пересечь ее и рассказанных ниже странных историях пост\n",
      "он должен был мысленно пересечь ее и рассказанных ниже странных историях посто\n",
      "он должен был мысленно пересечь ее и рассказанных ниже странных историях постоя\n",
      "он должен был мысленно пересечь ее и рассказанных ниже странных историях постоян\n",
      "он должен был мысленно пересечь ее и рассказанных ниже странных историях постоянн\n",
      "он должен был мысленно пересечь ее и рассказанных ниже странных историях постоянно\n",
      "он должен был мысленно пересечь ее и рассказанных ниже странных историях постоянно \n",
      "он должен был мысленно пересечь ее и рассказанных ниже странных историях постоянно п\n",
      "он должен был мысленно пересечь ее и рассказанных ниже странных историях постоянно пр\n",
      "он должен был мысленно пересечь ее и рассказанных ниже странных историях постоянно при\n",
      "он должен был мысленно пересечь ее и рассказанных ниже странных историях постоянно прис\n",
      "он должен был мысленно пересечь ее и рассказанных ниже странных историях постоянно прису\n",
      "он должен был мысленно пересечь ее и рассказанных ниже странных историях постоянно присут\n",
      "он должен был мысленно пересечь ее и рассказанных ниже странных историях постоянно присутс\n",
      "он должен был мысленно пересечь ее и рассказанных ниже странных историях постоянно присутст\n",
      "он должен был мысленно пересечь ее и рассказанных ниже странных историях постоянно присутств\n",
      "он должен был мысленно пересечь ее и рассказанных ниже странных историях постоянно присутству\n",
      "он должен был мысленно пересечь ее и рассказанных ниже странных историях постоянно присутствуе\n",
      "он должен был мысленно пересечь ее и рассказанных ниже странных историях постоянно присутствует\n",
      "он должен был мысленно пересечь ее и рассказанных ниже странных историях постоянно присутствует \n",
      "он должен был мысленно пересечь ее и рассказанных ниже странных историях постоянно присутствует э\n",
      "он должен был мысленно пересечь ее и рассказанных ниже странных историях постоянно присутствует эт\n",
      "он должен был мысленно пересечь ее и рассказанных ниже странных историях постоянно присутствует это\n",
      "он должен был мысленно пересечь ее и рассказанных ниже странных историях постоянно присутствует это \n",
      "он должен был мысленно пересечь ее и рассказанных ниже странных историях постоянно присутствует это н\n",
      "он должен был мысленно пересечь ее и рассказанных ниже странных историях постоянно присутствует это не\n",
      "он должен был мысленно пересечь ее и рассказанных ниже странных историях постоянно присутствует это неп\n",
      "он должен был мысленно пересечь ее и рассказанных ниже странных историях постоянно присутствует это непр\n",
      "он должен был мысленно пересечь ее и рассказанных ниже странных историях постоянно присутствует это непре\n",
      "он должен был мысленно пересечь ее и рассказанных ниже странных историях постоянно присутствует это непрер\n",
      "он должен был мысленно пересечь ее и рассказанных ниже странных историях постоянно присутствует это непреры\n",
      "он должен был мысленно пересечь ее и рассказанных ниже странных историях постоянно присутствует это непрерыв\n",
      "он должен был мысленно пересечь ее и рассказанных ниже странных историях постоянно присутствует это непрерывн\n",
      "он должен был мысленно пересечь ее и рассказанных ниже странных историях постоянно присутствует это непрерывно\n",
      "он должен был мысленно пересечь ее и рассказанных ниже странных историях постоянно присутствует это непрерывнос\n"
     ]
    }
   ],
   "source": [
    "# предсказание\n",
    "import operator\n",
    "\n",
    "def our_transition(pair, suf):\n",
    "    k, v = pair \n",
    "    return k.startswith(suf)\n",
    "        \n",
    "\n",
    "def predict(cur_line):\n",
    "    suf = cur_line[len(cur_line) - n_chars_to_consider:] \n",
    "    trs = dict()\n",
    "    for t in transitions.items():\n",
    "        k, v = t\n",
    "        if our_transition(t, suf):\n",
    "            trs[k] = v\n",
    "    if len(trs) == 0:\n",
    "        return None, True\n",
    "    \n",
    "    max_val = max(trs.values())\n",
    "    max_prob_key = max(trs, key = trs.get)\n",
    "    \n",
    "    next_char = max_prob_key[len(max_prob_key) - 1] #last \n",
    "    return cur_line + next_char, False\n",
    "\n",
    "print(\"Real sentence:\\n\", lines[sentence])\n",
    "print('Prompt: \"%s\"' % prompt)\n",
    "cur = prompt\n",
    "for i in range(100):\n",
    "    cur, ended = predict(cur)\n",
    "    if ended:\n",
    "        print('Достигли перехода в конец строки, всё')\n",
    "        break\n",
    "    print(cur)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "oAGY8ezK4sCU",
    "pgm1vifB4vnp"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
