{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qSFPOWRc4oUg"
   },
   "source": [
    "## Подготовка данных\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ouu7OCwY8jZx"
   },
   "source": [
    "Выбранный текст - Человек, который принял жену за шляпу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "id": "3wIk-ZuVB8wb"
   },
   "outputs": [],
   "source": [
    "#constants \n",
    "file_name = 'Человек,который_принял_жену_за_шляпу.pdf' # реальный текст романа с 14 по 112 страницы \n",
    "sentence_len = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CvhBHbdn4gQU",
    "outputId": "928edf99-81fa-451c-e5ec-2aa9fe9dbf2f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pdfquery in /Users/esoboleva/Library/Python/3.8/lib/python/site-packages (0.4.3)\n",
      "Requirement already satisfied: pdfminer.six in /Users/esoboleva/Library/Python/3.8/lib/python/site-packages (from pdfquery) (20221105)\n",
      "Requirement already satisfied: lxml>=3.0 in /Users/esoboleva/Library/Python/3.8/lib/python/site-packages (from pdfquery) (4.9.2)\n",
      "Requirement already satisfied: cssselect>=0.7.1 in /Users/esoboleva/Library/Python/3.8/lib/python/site-packages (from pdfquery) (1.2.0)\n",
      "Requirement already satisfied: chardet in /Users/esoboleva/Library/Python/3.8/lib/python/site-packages (from pdfquery) (5.1.0)\n",
      "Requirement already satisfied: roman>=1.4.0 in /Users/esoboleva/Library/Python/3.8/lib/python/site-packages (from pdfquery) (4.0)\n",
      "Requirement already satisfied: pyquery>=1.2.2 in /Users/esoboleva/Library/Python/3.8/lib/python/site-packages (from pdfquery) (2.0.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /Users/esoboleva/Library/Python/3.8/lib/python/site-packages (from pdfminer.six->pdfquery) (3.1.0)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /Users/esoboleva/Library/Python/3.8/lib/python/site-packages (from pdfminer.six->pdfquery) (40.0.2)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/esoboleva/Library/Python/3.8/lib/python/site-packages (from cryptography>=36.0.0->pdfminer.six->pdfquery) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /Users/esoboleva/Library/Python/3.8/lib/python/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->pdfquery) (2.21)\n",
      "\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.0.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.1.2\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001B[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /Library/Python/3.8/site-packages (1.5.3)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /Users/esoboleva/Library/Python/3.8/lib/python/site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Python/3.8/site-packages (from pandas) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Library/Python/3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas) (1.15.0)\n",
      "\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.0.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.1.2\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001B[0m\n",
      "Requirement already satisfied: nltk in /Users/esoboleva/Library/Python/3.8/lib/python/site-packages (3.8.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/esoboleva/Library/Python/3.8/lib/python/site-packages (from nltk) (2023.3.23)\n",
      "Requirement already satisfied: tqdm in /Users/esoboleva/Library/Python/3.8/lib/python/site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: click in /Users/esoboleva/Library/Python/3.8/lib/python/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in /Library/Python/3.8/site-packages (from nltk) (1.2.0)\n",
      "\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.0.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.1.2\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001B[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /Users/esoboleva/Library/Python/3.8/lib/python/site-packages (1.24.3)\n",
      "\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.0.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.1.2\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001B[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /Users/esoboleva/Library/Python/3.8/lib/python/site-packages (2.0.0)\n",
      "Requirement already satisfied: filelock in /Users/esoboleva/Library/Python/3.8/lib/python/site-packages (from torch) (3.12.0)\n",
      "Requirement already satisfied: networkx in /Users/esoboleva/Library/Python/3.8/lib/python/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: sympy in /Users/esoboleva/Library/Python/3.8/lib/python/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/esoboleva/Library/Python/3.8/lib/python/site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: jinja2 in /Users/esoboleva/Library/Python/3.8/lib/python/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/esoboleva/Library/Python/3.8/lib/python/site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/esoboleva/Library/Python/3.8/lib/python/site-packages (from sympy->torch) (1.3.0)\n",
      "\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.0.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.1.2\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install pdfquery\n",
    "! pip install pandas\n",
    "! pip install --user -U nltk\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install numpy\n",
    "\n",
    "! pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "from pdfquery import PDFQuery\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import nltk\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import re\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "id": "1eSu568VFLYF"
   },
   "outputs": [],
   "source": [
    "pdf = PDFQuery(file_name)\n",
    "pdf.load(*range(13, 53)) #TODO(\"увеличить?\")\n",
    "\n",
    "text_elements = pdf.pq('LTTextLineHorizontal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yVs0MDc9XEkM",
    "outputId": "c4b588ed-d3e9-46e2-9b79-8ef464d608d0"
   },
   "outputs": [],
   "source": [
    "text = \"\".join([t.text for t in text_elements]).replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ZsWeHIQ-W_P",
    "outputId": "e75e5e92-6996-4e96-b384-f2c04d718fb0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/esoboleva/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "id": "RxCpOdODax5n"
   },
   "outputs": [],
   "source": [
    "def tokenize_ru(file_text):\n",
    "    # firstly let's apply nltk tokenization\n",
    "    tokens = word_tokenize(file_text)\n",
    "\n",
    "    # let's delete punctuation symbols\n",
    "    tokens = [i for i in tokens if (i not in string.punctuation)]\n",
    "\n",
    "    # deleting other symbols\n",
    "    punct = ['—', ',', '.', '...']\n",
    "    tokens = [i for i in tokens if (i not in punct)]\n",
    "\n",
    "    # cleaning words\n",
    "    tokens = [re.sub(\"[a-z]\",\"\", re.sub(\"[0-9]\",\"\",\n",
    "              i.replace(\"«\", \"\")\n",
    "              .replace(\"»\", \"\")\n",
    "              .replace(\".\", \"\")\n",
    "              .replace(\"-\", \"\")\n",
    "              .replace('—', \"\")\n",
    "              .replace(',', \"\")\n",
    "              .replace('`', \"\")\n",
    "                                        \n",
    "              .lower()))\n",
    "              for i in tokens]\n",
    "    \n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "id": "kHN6VvpEax5o"
   },
   "outputs": [],
   "source": [
    "sentences = [tokenize_ru(sent) for sent in sent_tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oah7wL8max5q",
    "outputId": "d5082a45-23a4-44d2-f987-4c801654b81f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', \"'\", 'а', 'б', 'в', 'г', 'д', 'е', 'ж', 'з', 'и', 'й', 'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф', 'х', 'ц', 'ч', 'ш', 'щ', 'ъ', 'ы', 'ь', 'э', 'ю', 'я']\n",
      "Symbols count:  129586\n",
      "Sentences count:  751\n"
     ]
    }
   ],
   "source": [
    "alphabet = {'\\n'}\n",
    "\n",
    "loaded_text_path = 'text.txt'\n",
    "text_file = open(loaded_text_path, \"w\")\n",
    "\n",
    "for s in sentences:\n",
    "    joined_s = \" \".join(s)\n",
    "    if len(joined_s) > sentence_len:\n",
    "        text_file.write(joined_s)\n",
    "        text_file.write('\\n')\n",
    "        # getting alphabet\n",
    "        for c in joined_s:\n",
    "            alphabet.add(c)\n",
    "text_file.close()\n",
    "alphabet = sorted(alphabet)\n",
    "print(alphabet)\n",
    "n_vocab = len(alphabet)\n",
    "\n",
    "text = open(\"text.txt\").read()\n",
    "sentences = open(\"text.txt\").readlines()\n",
    "print('Symbols count: ', len(text))\n",
    "print('Sentences count: ', len(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wWxqCwovax5r"
   },
   "source": [
    "остались только кириллица и пробел - ура\n",
    "\n",
    "сделаем one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "id": "zBzT41Mjax5r"
   },
   "outputs": [],
   "source": [
    "int_to_vocab = {ii:word for ii, word in enumerate(alphabet)}\n",
    "vocab_to_int = {word:ii for ii, word in int_to_vocab.items()}\n",
    "\n",
    "def encode_text(text):\n",
    "    int_text = [vocab_to_int[word] for word in text]\n",
    "\n",
    "    one_hot_text = []\n",
    "    for c in int_text:\n",
    "        cur = np.zeros(n_vocab, dtype=int)\n",
    "        cur[c] = 1\n",
    "        one_hot_text.append(cur)\n",
    "    return one_hot_text\n",
    "\n",
    "\n",
    "def batch_data(text, sequence_length, batch_size):\n",
    "    n_batches = len(text)//batch_size\n",
    "    x, y = [], []\n",
    "    text = text[:n_batches*batch_size]\n",
    "    \n",
    "    for ii in range(0, len(text)-sequence_length):\n",
    "        i_end = ii+sequence_length        \n",
    "        batch_x = text[ii:ii+sequence_length]\n",
    "        x.append(batch_x)\n",
    "        batch_y = text[i_end]\n",
    "        y.append(batch_y)\n",
    "    \n",
    "    data = torch.from_numpy(np.asarray(x)), torch.from_numpy(np.asarray(y))\n",
    "        \n",
    "    return data\n",
    "\n",
    "def to_loader(data, batch_size):\n",
    "    return DataLoader(TensorDataset(*data), shuffle=True, batch_size=batch_size)\n",
    "\n",
    "\n",
    "one_hot_text = encode_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oAGY8ezK4sCU"
   },
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "id": "4RvEwPWZax5u"
   },
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=n_vocab, hidden_size=256, num_layers=3, batch_first=True)\n",
    "#         self.dropout = nn.Dropout(0.5)\n",
    "        self.linear = nn.Linear(256, n_vocab)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = x[:, -1, :] \n",
    "        # produce output\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 128\n",
    "model = RNNModel()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "train_loader = to_loader(batch_data(one_hot_text, sentence_len, batch_size), batch_size)\n",
    "\n",
    "best_model = None\n",
    "best_loss = np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Cross-entropy: 2.4539\n",
      "Epoch 1: Cross-entropy: 1.7686\n",
      "Epoch 2: Cross-entropy: 1.6093\n",
      "Epoch 3: Cross-entropy: 1.1163\n",
      "Epoch 4: Cross-entropy: 1.3546\n",
      "Epoch 5: Cross-entropy: 1.3182\n",
      "Epoch 6: Cross-entropy: 1.2285\n",
      "Epoch 7: Cross-entropy: 0.8202\n",
      "Epoch 8: Cross-entropy: 0.9289\n",
      "Epoch 9: Cross-entropy: 0.6384\n",
      "Epoch 10: Cross-entropy: 0.5816\n",
      "Epoch 11: Cross-entropy: 0.7738\n",
      "Epoch 12: Cross-entropy: 0.8788\n",
      "Epoch 13: Cross-entropy: 0.6497\n",
      "Epoch 14: Cross-entropy: 0.6951\n",
      "Epoch 15: Cross-entropy: 0.7154\n",
      "Epoch 16: Cross-entropy: 0.9325\n",
      "Epoch 17: Cross-entropy: 0.4460\n",
      "Epoch 18: Cross-entropy: 0.3368\n",
      "Epoch 19: Cross-entropy: 0.1637\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch = X_batch.to(torch.float32)\n",
    "        y_pred = model(X_batch)\n",
    "        \n",
    "        y_pred = y_pred.to(torch.float32)\n",
    "        y_batch = y_batch.to(torch.float32)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch = X_batch.to(torch.float32)\n",
    "            y_pred = model(X_batch)\n",
    "            y_pred = y_pred.to(torch.float32)\n",
    "            y_batch = y_batch.to(torch.float32)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            best_model = model.state_dict()\n",
    "        print(\"Epoch %d: Cross-entropy: %.4f\" % (epoch, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model, \"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('text.txt', 'r')\n",
    "lines = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNNModel()\n",
    "model.load_state_dict(torch.load(\"model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_len = 20\n",
    "sentence = np.random.randint(len(lines))\n",
    "prompt = lines[sentence][0:prompt_len]\n",
    "\n",
    "one_hot_prompt = encode_text(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:  столь абсурдные ошиб\n",
      "столь абсурдные ошиббкио тсоктуо тсиятл юи  впеорбее  вч еуг одвнеяс нвачнноый  рпаантиемм иин упзоаввлеянсык  ио драумсетв яи твроотн оеб оэднуаж иул едгуо  им пдрииммиастьию ткаан ии  всоявлшие  дсоятхеют  дионтаонваалщье  ив  сттаантиив аквтирке   сввеетшсея  тноувлеен ск осбоелм иил ивзеалт н апвиатлиас ьи  сслиабтеу твуодсак  силн овбоелмие  ввиедмуу  коагнроамтиартноомтиалщиях  прооббрааттиех  аонтоанлиий  пкроимхе тврооа  ии  псоибзоилтин овблаодтаи  птроидзеанттеийн \n",
      "вколрлеяв  еящ еищ еищ еиг реезл обтнаоя\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "print(\"Prompt: \", prompt)\n",
    "print(prompt, end=\"\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(500):\n",
    "        \n",
    "        one_hot_prompt = encode_text(prompt)\n",
    "        x, y = batch_data(one_hot_prompt, prompt_len - 1, 1)\n",
    "        x = x.to(torch.float32)\n",
    "        \n",
    "        prediction = model(x)\n",
    "        index = int(prediction.argmax())\n",
    "\n",
    "        result = int_to_vocab[index]\n",
    "        print(result, end=\"\")\n",
    "\n",
    "        prompt = prompt + result\n",
    "        prompt = prompt[1:]\n",
    "\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pgm1vifB4vnp"
   },
   "source": [
    "## Марковская цепь\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "id": "WcGpS4nL46-W"
   },
   "outputs": [],
   "source": [
    "n_chars_to_consider = 6\n",
    "transitions = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "id": "-KYqL3Sjax5v"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transitions count:  81375\n"
     ]
    }
   ],
   "source": [
    "for s in lines:\n",
    "    prev = None\n",
    "    i = 0\n",
    "    while i < len(s):\n",
    "        if prev == None:\n",
    "            prev = s[:n_chars_to_consider]\n",
    "            i += n_chars_to_consider\n",
    "            continue\n",
    "        new_state = prev[1:] + s[i]\n",
    "        key = prev + '->' + new_state\n",
    "        if not (key in transitions):\n",
    "            transitions[key] = 1\n",
    "        else:\n",
    "            transitions[key] += 1\n",
    "        prev = new_state\n",
    "        i+=1\n",
    "\n",
    "# нормируем\n",
    "summ = 0\n",
    "for t in transitions.values():\n",
    "    summ += t\n",
    "\n",
    "transitions = {k: v / summ for k, v in transitions.items()}\n",
    "print(\"Transitions count: \", len(transitions.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_len = 11 # > n_chars_to_consider\n",
    "\n",
    "sentence = np.random.randint(len(lines))\n",
    "prompt = lines[sentence][0:prompt_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real sentence:\n",
      " однако и здесь возможности эмили д были ограничены поскольку зрение ее быстро ухудшалось изза злокачественной глаукомы\n",
      "\n",
      "Prompt: \"однако и зд\"\n",
      "однако и зде\n",
      "однако и здес\n",
      "однако и здесь\n",
      "однако и здесь \n",
      "однако и здесь в\n",
      "однако и здесь ви\n",
      "однако и здесь вит\n",
      "однако и здесь витг\n",
      "однако и здесь витге\n",
      "однако и здесь витген\n",
      "однако и здесь витгенш\n",
      "однако и здесь витгеншт\n",
      "однако и здесь витгенште\n",
      "однако и здесь витгенштей\n",
      "однако и здесь витгенштейн\n",
      "однако и здесь витгенштейна\n",
      "однако и здесь витгенштейна \n",
      "однако и здесь витгенштейна и\n",
      "однако и здесь витгенштейна и \n",
      "однако и здесь витгенштейна и д\n",
      "однако и здесь витгенштейна и др\n",
      "однако и здесь витгенштейна и дру\n",
      "однако и здесь витгенштейна и друг\n",
      "однако и здесь витгенштейна и други\n",
      "однако и здесь витгенштейна и других\n",
      "однако и здесь витгенштейна и других \n",
      "однако и здесь витгенштейна и других н\n",
      "однако и здесь витгенштейна и других не\n",
      "однако и здесь витгенштейна и других нез\n",
      "однако и здесь витгенштейна и других неза\n",
      "однако и здесь витгенштейна и других незам\n",
      "однако и здесь витгенштейна и других незаме\n",
      "однако и здесь витгенштейна и других незамет\n",
      "однако и здесь витгенштейна и других незаметн\n",
      "однако и здесь витгенштейна и других незаметно\n",
      "однако и здесь витгенштейна и других незаметно \n",
      "однако и здесь витгенштейна и других незаметно р\n",
      "однако и здесь витгенштейна и других незаметно ра\n",
      "однако и здесь витгенштейна и других незаметно рас\n",
      "однако и здесь витгенштейна и других незаметно расс\n",
      "однако и здесь витгенштейна и других незаметно расст\n",
      "однако и здесь витгенштейна и других незаметно расстр\n",
      "однако и здесь витгенштейна и других незаметно расстро\n",
      "однако и здесь витгенштейна и других незаметно расстрой\n",
      "однако и здесь витгенштейна и других незаметно расстройс\n",
      "однако и здесь витгенштейна и других незаметно расстройст\n",
      "однако и здесь витгенштейна и других незаметно расстройств\n",
      "однако и здесь витгенштейна и других незаметно расстройства\n",
      "однако и здесь витгенштейна и других незаметно расстройства \n",
      "однако и здесь витгенштейна и других незаметно расстройства с\n",
      "однако и здесь витгенштейна и других незаметно расстройства се\n",
      "однако и здесь витгенштейна и других незаметно расстройства сер\n",
      "однако и здесь витгенштейна и других незаметно расстройства серь\n",
      "однако и здесь витгенштейна и других незаметно расстройства серье\n",
      "однако и здесь витгенштейна и других незаметно расстройства серьез\n",
      "однако и здесь витгенштейна и других незаметно расстройства серьезн\n",
      "однако и здесь витгенштейна и других незаметно расстройства серьезны\n",
      "однако и здесь витгенштейна и других незаметно расстройства серьезным\n",
      "однако и здесь витгенштейна и других незаметно расстройства серьезными\n",
      "однако и здесь витгенштейна и других незаметно расстройства серьезными \n",
      "однако и здесь витгенштейна и других незаметно расстройства серьезными с\n",
      "однако и здесь витгенштейна и других незаметно расстройства серьезными сп\n",
      "однако и здесь витгенштейна и других незаметно расстройства серьезными спо\n",
      "однако и здесь витгенштейна и других незаметно расстройства серьезными спос\n",
      "однако и здесь витгенштейна и других незаметно расстройства серьезными спосо\n",
      "однако и здесь витгенштейна и других незаметно расстройства серьезными способ\n",
      "однако и здесь витгенштейна и других незаметно расстройства серьезными способн\n",
      "однако и здесь витгенштейна и других незаметно расстройства серьезными способно\n",
      "однако и здесь витгенштейна и других незаметно расстройства серьезными способнос\n",
      "однако и здесь витгенштейна и других незаметно расстройства серьезными способност\n",
      "однако и здесь витгенштейна и других незаметно расстройства серьезными способность\n",
      "однако и здесь витгенштейна и других незаметно расстройства серьезными способность \n",
      "однако и здесь витгенштейна и других незаметно расстройства серьезными способность и\n",
      "однако и здесь витгенштейна и других незаметно расстройства серьезными способность и \n",
      "однако и здесь витгенштейна и других незаметно расстройства серьезными способность и в\n",
      "однако и здесь витгенштейна и других незаметно расстройства серьезными способность и во\n",
      "однако и здесь витгенштейна и других незаметно расстройства серьезными способность и воз\n",
      "однако и здесь витгенштейна и других незаметно расстройства серьезными способность и возв\n",
      "однако и здесь витгенштейна и других незаметно расстройства серьезными способность и возвр\n",
      "однако и здесь витгенштейна и других незаметно расстройства серьезными способность и возвра\n",
      "однако и здесь витгенштейна и других незаметно расстройства серьезными способность и возвращ\n",
      "однако и здесь витгенштейна и других незаметно расстройства серьезными способность и возвраще\n",
      "однако и здесь витгенштейна и других незаметно расстройства серьезными способность и возвращен\n",
      "однако и здесь витгенштейна и других незаметно расстройства серьезными способность и возвращени\n",
      "однако и здесь витгенштейна и других незаметно расстройства серьезными способность и возвращение\n",
      "однако и здесь витгенштейна и других незаметно расстройства серьезными способность и возвращение \n",
      "однако и здесь витгенштейна и других незаметно расстройства серьезными способность и возвращение к\n",
      "однако и здесь витгенштейна и других незаметно расстройства серьезными способность и возвращение ко\n",
      "однако и здесь витгенштейна и других незаметно расстройства серьезными способность и возвращение кон\n",
      "однако и здесь витгенштейна и других незаметно расстройства серьезными способность и возвращение коне\n",
      "однако и здесь витгенштейна и других незаметно расстройства серьезными способность и возвращение конеч\n",
      "однако и здесь витгенштейна и других незаметно расстройства серьезными способность и возвращение конечн\n",
      "однако и здесь витгенштейна и других незаметно расстройства серьезными способность и возвращение конечно\n",
      "однако и здесь витгенштейна и других незаметно расстройства серьезными способность и возвращение конечнос\n",
      "однако и здесь витгенштейна и других незаметно расстройства серьезными способность и возвращение конечност\n",
      "однако и здесь витгенштейна и других незаметно расстройства серьезными способность и возвращение конечносте\n",
      "однако и здесь витгенштейна и других незаметно расстройства серьезными способность и возвращение конечностей\n",
      "однако и здесь витгенштейна и других незаметно расстройства серьезными способность и возвращение конечностей \n",
      "однако и здесь витгенштейна и других незаметно расстройства серьезными способность и возвращение конечностей с\n",
      "однако и здесь витгенштейна и других незаметно расстройства серьезными способность и возвращение конечностей со\n"
     ]
    }
   ],
   "source": [
    "# предсказание\n",
    "import operator\n",
    "\n",
    "def our_transition(pair, suf):\n",
    "    k, v = pair \n",
    "    return k.startswith(suf)\n",
    "        \n",
    "\n",
    "def predict(cur_line):\n",
    "    suf = cur_line[len(cur_line) - n_chars_to_consider:] \n",
    "    trs = dict()\n",
    "    for t in transitions.items():\n",
    "        k, v = t\n",
    "        if our_transition(t, suf):\n",
    "            trs[k] = v\n",
    "    if len(trs) == 0:\n",
    "        return None, True\n",
    "    \n",
    "    max_val = max(trs.values())\n",
    "    max_prob_key = max(trs, key = trs.get)\n",
    "    \n",
    "    next_char = max_prob_key[len(max_prob_key) - 1] #last \n",
    "    return cur_line + next_char, False\n",
    "\n",
    "print(\"Real sentence:\\n\", lines[sentence])\n",
    "print('Prompt: \"%s\"' % prompt)\n",
    "cur = prompt\n",
    "for i in range(100):\n",
    "    cur, ended = predict(cur)\n",
    "    if ended:\n",
    "        print('Достигли перехода в конец строки, всё')\n",
    "        break\n",
    "    print(cur)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "oAGY8ezK4sCU",
    "pgm1vifB4vnp"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
